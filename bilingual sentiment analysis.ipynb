{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8302473-1378-4cc1-a904-2d5b5e53f954",
   "metadata": {},
   "source": [
    "# Machine Translation Based on Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd6be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebbff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output before preprocessing is:  \n",
      " <start> I like this book <end>\n",
      "The output before preprocessing is:  \n",
      " <start> 我喜欢这本书 <end> utf-8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets\n",
    "def preprocess_sentence(w):   \n",
    "    '''\n",
    "    w：sentence\n",
    "    '''\n",
    "    w = re.sub(r'([?.!,])', r' \\1 ', w)  # add spaces before and after punctuation marks in sentences\n",
    "    w = re.sub(r\"[' ']+\", ' ', w)  # remove multiple spaces from sentences\n",
    "    w = '<start> ' + w + ' <end>'  # add start and end marks to the sentences so that the model can predict them\n",
    "    return w\n",
    "\n",
    "en_sentence = 'I like this book'\n",
    "sp_sentence = '我喜欢这本书'\n",
    "print('The output before preprocessing is: ', '\\n', preprocess_sentence(en_sentence))\n",
    "print('The output before preprocessing is: ', '\\n', str(preprocess_sentence(sp_sentence)), 'utf-8', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26c5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up sentences, remove accents, and return word pairs in format [English, Chinese]\n",
    "def create_dataset(path, num_examples):\n",
    "    '''\n",
    "    path：file path\n",
    "    num_examples：the amount of data selected\n",
    "    '''\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "path_to_file = '../data/en-ch.txt'  # path to read the file\n",
    "en, sp = create_dataset(path_to_file, None)  # cosolidate and read the data\n",
    "# None--> indicates that the function does not limit the number of sentences read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292f07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sentence length\n",
    "def max_length(tensor):\n",
    "    '''\n",
    "    tensor：the tensor of text composition\n",
    "    '''\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cecf260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    '''\n",
    "    lang：text to be processed\n",
    "    '''\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang) # generate a document dictionary\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2ccfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean input/output pair\n",
    "def load_dataset(path, num_examples=None):\n",
    "    '''\n",
    "    path：file path\n",
    "    num_examples：the amount of data selected\n",
    "    '''\n",
    "    # create an index, imput the cleaned words, output word pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples) \n",
    "    # establish the word vector of Chinese sentence, fill all tensors-->sentences has the same dimension\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)   \n",
    "    # establish the word vector of English sentence, fill all tensors-->sentences has the same dimension\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)  \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3900f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 2000  # size of the vocabulary (词量)\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, \n",
    "                                                                num_examples)\n",
    "# calculate the maximum length of the target tensor\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(\n",
    "    input_tensor) \n",
    "\n",
    "# the training set and the verification set are divided by the ratio of 8:2\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
    "        input_tensor, target_tensor, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb23b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output before preprocessing is: \n",
      "Input language: Word mapping index\n",
      "1 ----> <start>\n",
      "512 ----> 汤姆告诉了他。\n",
      "2 ----> <end>\n",
      "Target language: Word mapping index\n",
      "1 ----> <start>\n",
      "10 ----> tom\n",
      "330 ----> told\n",
      "39 ----> him\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "# Verify the correctness of the data-->the representation of the output word and the word mapping index\n",
    "def convert(lang, tensor):\n",
    "    '''\n",
    "    lang：text to be processed\n",
    "    tensor：the tensor of text composition\n",
    "    '''\n",
    "    for t in tensor:\n",
    "        if t != 0:    \n",
    "            print ('%d ----> %s' % (t, lang.index_word[t]))\n",
    "\n",
    "print('The output before preprocessing is: ')\n",
    "print('Input language: Word mapping index')\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print('Target language: Word mapping index')\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba23d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf.data dataset\n",
    "BUFFER_SIZE = len(input_tensor_train)  # the maximum number of elements to be added to the buffer\n",
    "BATCH_SIZE = 64  # the number of samples selected for each training\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE  # the number of iteration steps required to train a round\n",
    "embedding_dim = 256  # dimension of word vector\n",
    "units = 1024  # number of neurons\n",
    "vocab_inp_size = len(inp_lang.word_index)+1  # input the size of the vocabulary\n",
    "vocab_tar_size = len(targ_lang.word_index)+1  # output the size of the vocabulary\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)  # build training set\n",
    "example_input_batch, example_target_batch = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed35d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz  # the number of samples selected for each training\n",
    "        self.enc_units = enc_units  # number of neurons\n",
    "        #input\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)  \n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8711e0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: \n",
      "  (batch size, sequence length, units) (64, 6, 1024)\n",
      "Encoder hidden state shape: \n",
      "  (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Construct the encoder network structure    \n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_hidden = encoder.initialize_hidden_state()  # input hidden sample\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)  \n",
    "print('Encoder output shape:', '\\n', ' (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print('Encoder hidden state shape:', '\\n', ' (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "123b9448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attentional result shape:  \n",
      "  (batch size, units) (64, 1024)\n",
      "Attention weight shape:  \n",
      "  (batch_size, sequence_length, 1) (64, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "# Attention mechanism\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)  \n",
    "        # Calculate the attention weight value\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))  \n",
    "        # attention_weights shape == （batch size，max_length，1）\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # context_vector sum shape == (batch size, hidden layer size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "attention_layer = BahdanauAttention(10)  # construct attention network structure\n",
    "attention_result, attention_weights = attention_layer(\n",
    "    sample_hidden, sample_output)\n",
    "print('Attentional result shape: ', '\\n', ' (batch size, units) {}'.format(attention_result.shape)) \n",
    "print('Attention weight shape: ', '\\n', ' (batch_size, sequence_length, 1) {}'.format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d72285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: \n",
      "  (batch_size, vocab size) (64, 1166)\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz  # the number of samples selected for each training\n",
    "        self.dec_units = dec_units  # number of neurons\n",
    "        # input layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)  \n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        # call attention model\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x) \n",
    "        output = tf.reshape(output, (-1, output.shape[2])) \n",
    "\n",
    "        x = self.fc(output)  \n",
    "        return x, state, attention_weights\n",
    "    \n",
    "# build decoder network structure\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)  \n",
    "sample_decoder_output, states, attention_weight = decoder(tf.random.uniform((64, 1)), sample_hidden, sample_output)\n",
    "print('Decoder output shape:', '\\n', ' (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f7028eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()  \n",
    "# Loss object\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')  \n",
    "\n",
    "# Define the optimizer and the loss function\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82d59ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d3ffced",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../tmp/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)  # save the model\n",
    "# train the model\n",
    "def train(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)  # build encoder\n",
    "        dec_hidden = enc_hidden  \n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # transfer the encoder output to the decoder\n",
    "            predictions, dec_hidden, dec_predictions = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        loss = loss / int(targ.shape[1])  # calculate average loss\n",
    "    batch_loss = loss.numpy()  # convert losses to numpy arrays\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e90dd90d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.5246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:29<24:24, 29.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 0 Loss 2.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:55<22:05, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 0 Loss 2.3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:28<23:26, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 0 Loss 2.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [02:02<24:02, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 0 Loss 1.9503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [02:27<21:48, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 0 Loss 1.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [03:00<22:26, 30.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 0 Loss 1.7096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [03:33<22:25, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 0 Loss 1.7637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [04:03<21:43, 31.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 0 Loss 1.6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [04:26<19:22, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 0 Loss 1.5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [04:54<18:46, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 0 Loss 1.3991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [05:23<18:34, 28.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 0 Loss 1.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [05:53<18:21, 28.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 0 Loss 1.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [06:18<17:10, 27.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 0 Loss 1.2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [06:39<15:27, 25.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 0 Loss 1.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [07:00<14:13, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 0 Loss 1.0724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [07:23<13:34, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 0 Loss 0.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [07:47<13:03, 23.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 0 Loss 0.9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [08:11<12:42, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 0 Loss 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [08:37<12:38, 24.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 0 Loss 0.7902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [09:02<12:19, 24.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 0 Loss 0.7896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [09:26<11:47, 24.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 0 Loss 0.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [09:52<11:37, 24.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 0 Loss 0.6455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [10:14<10:53, 24.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 0 Loss 0.5670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [10:36<10:12, 23.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 0 Loss 0.5822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [10:59<09:40, 23.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 0 Loss 0.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [11:22<09:19, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 0 Loss 0.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [11:47<09:04, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 0 Loss 0.4758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [12:09<08:29, 23.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 0 Loss 0.4815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [12:33<08:12, 23.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 0 Loss 0.4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [12:58<08:00, 24.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 0 Loss 0.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [13:24<07:44, 24.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 0 Loss 0.3495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [13:55<07:58, 26.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 0 Loss 0.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [14:23<07:39, 27.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 0 Loss 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [14:56<07:37, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 0 Loss 0.2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [15:26<07:17, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 0 Loss 0.2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [15:55<06:48, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 0 Loss 0.1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [16:25<06:22, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 0 Loss 0.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [16:56<05:57, 29.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 0 Loss 0.1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [17:26<05:28, 29.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 0 Loss 0.1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [17:59<05:09, 30.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 0 Loss 0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [18:33<04:45, 31.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 0 Loss 0.1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [19:04<04:12, 31.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 0 Loss 0.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [19:36<03:42, 31.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 0 Loss 0.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [20:07<03:09, 31.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 0 Loss 0.0699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [20:39<02:37, 31.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 0 Loss 0.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [21:12<02:08, 32.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 0 Loss 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [21:42<01:34, 31.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 0 Loss 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [22:14<01:02, 31.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 0 Loss 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [22:45<00:31, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 0 Loss 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [23:17<00:00, 27.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Begin training\n",
    "EPOCHS = 50\n",
    "loss = []\n",
    "from tqdm import  tqdm\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "    enc_hidden = encoder.initialize_hidden_state()  # initializes the hidden layer\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        # print(batch)\n",
    "        batch_loss = train(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "            loss.append(round(batch_loss, 3))\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6142726f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss trend visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # Set the font to bold\n",
    "plt.rcParams['axes.unicode_minus'] = False  # Display Settings for characters\n",
    "plt.plot(list(range(1, 51)), loss)  # Plot the loss value as a line chart\n",
    "plt.title('Loss trend chart', fontsize=16)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Lost value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "180ac992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd956649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate\n",
    "def evaluate(sentence):\n",
    "    '''\n",
    "    sentence：sentences that need to be translated\n",
    "    '''\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        # The predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b797aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "def translate(sentence):\n",
    "    '''\n",
    "    sentence：sentences that need to be translated\n",
    "    '''\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    processed_result = result.replace('<end>', '').strip()\n",
    "    return '{}'.format(processed_result)\n",
    "#     print('Input: %s' % (sentence))\n",
    "#     print('translation result: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a93e1-8172-4819-ba76-c090e488546e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Based on LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6b592af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84eeab23-f60e-4306-ac9e-7e6d79cd77be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "joy        2326\n",
      "sadness    2317\n",
      "anger      2259\n",
      "neutral    2254\n",
      "fear       2171\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When my family heard that my Mother's cousin w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so...\n",
       "5  sadness  When my family heard that my Mother's cousin w..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('data/data_train.csv', encoding='utf-8')\n",
    "data_test = pd.read_csv('data/data_test.csv', encoding='utf-8')\n",
    "\n",
    "# data = data_train.append(data_test, ignore_index=True)\n",
    "data = pd.concat([data_train, data_test], ignore_index=True)\n",
    "\n",
    "print(data.Emotion.value_counts())\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d89a0ca-5dbc-4934-9a5d-a2d6ef44747b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>sadness</td>\n",
       "      <td>My sweetheart left me , or rather we decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Well , it 's too bad that we like different ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>neutral</td>\n",
       "      <td>It sure is .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>sadness</td>\n",
       "      <td>He ’ s got laid off again . I do feel sorry fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11326</th>\n",
       "      <td>anger</td>\n",
       "      <td>When stupid people push me during rush time in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Emotion                                               Text\n",
       "0      neutral  There are tons of other paintings that I think...\n",
       "1      sadness  Yet the dog had grown old and less capable , a...\n",
       "2         fear  When I get into the tube or the train without ...\n",
       "3         fear  This last may be a source of considerable disq...\n",
       "4        anger  She disliked the intimacy he showed towards so...\n",
       "...        ...                                                ...\n",
       "11322  sadness  My sweetheart left me , or rather we decided t...\n",
       "11323  sadness  Well , it 's too bad that we like different ki...\n",
       "11324  neutral                                       It sure is .\n",
       "11325  sadness  He ’ s got laid off again . I do feel sorry fo...\n",
       "11326    anger  When stupid people push me during rush time in...\n",
       "\n",
       "[11327 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(data):\n",
    "    \n",
    "    # remove hashtags and @usernames\n",
    "    data = re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
    "    data = re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
    "    \n",
    "    # tekenization using nltk\n",
    "    data = word_tokenize(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data['Text'] = [' '.join(clean_text(text)) for text in data.Text]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48f4d68b-0156-4c23-9ddd-75dad33a6b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I think...</td>\n",
       "      <td>[There, are, tons, of, other, paintings, that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "      <td>[Yet, the, dog, had, grown, old, and, less, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "      <td>[When, I, get, into, the, tube, or, the, train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "      <td>[This, last, may, be, a, source, of, considera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "      <td>[She, disliked, the, intimacy, he, showed, tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>sadness</td>\n",
       "      <td>My sweetheart left me , or rather we decided t...</td>\n",
       "      <td>[My, sweetheart, left, me, ,, or, rather, we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Well , it 's too bad that we like different ki...</td>\n",
       "      <td>[Well, ,, it, 's, too, bad, that, we, like, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>neutral</td>\n",
       "      <td>It sure is .</td>\n",
       "      <td>[It, sure, is, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>sadness</td>\n",
       "      <td>He ’ s got laid off again . I do feel sorry fo...</td>\n",
       "      <td>[He, ’, s, got, laid, off, again, ., I, do, fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11326</th>\n",
       "      <td>anger</td>\n",
       "      <td>When stupid people push me during rush time in...</td>\n",
       "      <td>[When, stupid, people, push, me, during, rush,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11327 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Emotion                                               Text  \\\n",
       "0      neutral  There are tons of other paintings that I think...   \n",
       "1      sadness  Yet the dog had grown old and less capable , a...   \n",
       "2         fear  When I get into the tube or the train without ...   \n",
       "3         fear  This last may be a source of considerable disq...   \n",
       "4        anger  She disliked the intimacy he showed towards so...   \n",
       "...        ...                                                ...   \n",
       "11322  sadness  My sweetheart left me , or rather we decided t...   \n",
       "11323  sadness  Well , it 's too bad that we like different ki...   \n",
       "11324  neutral                                       It sure is .   \n",
       "11325  sadness  He ’ s got laid off again . I do feel sorry fo...   \n",
       "11326    anger  When stupid people push me during rush time in...   \n",
       "\n",
       "                                                   words  \n",
       "0      [There, are, tons, of, other, paintings, that,...  \n",
       "1      [Yet, the, dog, had, grown, old, and, less, ca...  \n",
       "2      [When, I, get, into, the, tube, or, the, train...  \n",
       "3      [This, last, may, be, a, source, of, considera...  \n",
       "4      [She, disliked, the, intimacy, he, showed, tow...  \n",
       "...                                                  ...  \n",
       "11322  [My, sweetheart, left, me, ,, or, rather, we, ...  \n",
       "11323  [Well, ,, it, 's, too, bad, that, we, like, di...  \n",
       "11324                                  [It, sure, is, .]  \n",
       "11325  [He, ’, s, got, laid, off, again, ., I, do, fe...  \n",
       "11326  [When, stupid, people, push, me, during, rush,...  \n",
       "\n",
       "[11327 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_word = lambda x: list(word_tokenize(x))\n",
    "data['words'] = data['Text'].apply(cut_word)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf2e2307-08d8-4c10-893f-fc9580ecd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "for i in data['words']:\n",
    "    w.extend(i)\n",
    "dicts = pd.DataFrame(pd.Series(w).value_counts())\n",
    "\n",
    "dicts['id'] = list(range(1, len(dicts)+1))\n",
    "\n",
    "get_sent = lambda x: list(dicts['id'][x])\n",
    "data['sent'] = data['words'].apply(get_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "675f3a3b-e111-4f25-ad00-7c52611505ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "maxlen = 40\n",
    "data['sent'] = list(sequence.pad_sequences(data['sent'], maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "394a460d-86b0-4cd7-85b4-3eeaffa60a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    'joy': 0,\n",
    "    'fear': 1,\n",
    "    'anger': 2,\n",
    "    'sadness': 3,\n",
    "    'neutral': 4\n",
    "}\n",
    "\n",
    "# Integer labels\n",
    "data['mark'] = [encoding[x] for x in data['Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7ba9db7-0eac-4883-a5c4-c2735e34c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.array(list(data['sent']))\n",
    "y_all = np.array(list(data['mark']))\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_all, y_all, test_size=0.25)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16e0fc20-52a3-4c48-9834-d3ef37dbf9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sent shape of data:  (8495, 40)\n",
      "train mark shape of data:  (8495, 5)\n",
      "validation sent shape of data:  (2832, 40)\n",
      "validation mark shape of data:  (2832, 5)\n",
      "train sent of data: \n",
      " [[   0    0    0 ...   14  127    1]\n",
      " [   0    0    0 ... 1650 1540    1]\n",
      " [   0    0    0 ... 5241 3579    1]\n",
      " ...\n",
      " [   0    0    0 ...    6  104    1]\n",
      " [   0    0    0 ...   18   61   23]\n",
      " [   0    0    0 ...  202  389   81]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_validation = to_categorical(y_validation)\n",
    "\n",
    "print('train sent shape of data: ', x_train.shape)\n",
    "print('train mark shape of data: ', y_train.shape)\n",
    "print('validation sent shape of data: ', x_validation.shape)\n",
    "print('validation mark shape of data: ', y_validation.shape)\n",
    "\n",
    "print('train sent of data: \\n', x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "689d365f-18fb-41a3-95e4-3f526eac40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3748e935-6096-410b-a345-fe787a0ae88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 40, 256)           3642112   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 40, 128)           197120    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,971,461\n",
      "Trainable params: 3,971,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(dicts)+1, 256, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "import time\n",
    "# hyperparameter\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c228b353-31bd-4c62-817b-1a9fd0aec8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "531/531 [==============================] - 33s 49ms/step - loss: 1.1890 - accuracy: 0.5089\n",
      "Epoch 2/10\n",
      "531/531 [==============================] - 25s 48ms/step - loss: 0.6031 - accuracy: 0.7972\n",
      "Epoch 3/10\n",
      "531/531 [==============================] - 27s 50ms/step - loss: 0.3634 - accuracy: 0.8825\n",
      "Epoch 4/10\n",
      "531/531 [==============================] - 28s 53ms/step - loss: 0.2566 - accuracy: 0.9230\n",
      "Epoch 5/10\n",
      "531/531 [==============================] - 28s 52ms/step - loss: 0.1831 - accuracy: 0.9462\n",
      "Epoch 6/10\n",
      "531/531 [==============================] - 28s 52ms/step - loss: 0.1427 - accuracy: 0.9595\n",
      "Epoch 7/10\n",
      "531/531 [==============================] - 27s 51ms/step - loss: 0.1227 - accuracy: 0.9644\n",
      "Epoch 8/10\n",
      "531/531 [==============================] - 28s 52ms/step - loss: 0.1042 - accuracy: 0.9669\n",
      "Epoch 9/10\n",
      "531/531 [==============================] - 28s 52ms/step - loss: 0.0919 - accuracy: 0.9725\n",
      "Epoch 10/10\n",
      "531/531 [==============================] - 28s 53ms/step - loss: 0.0812 - accuracy: 0.9759\n",
      "time cost： 279\n"
     ]
    }
   ],
   "source": [
    "timeA = time.time()\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "timeB = time.time()\n",
    "print('time cost：', int(timeB-timeA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af52a3f4-b27c-4abb-8e7a-8decba6dd8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 3s 13ms/step\n",
      "accuracy of validation 0.684322033898305\n",
      "precision, recall, F1 score: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69       603\n",
      "           1       0.62      0.73      0.67       541\n",
      "           2       0.64      0.63      0.63       566\n",
      "           3       0.65      0.67      0.66       570\n",
      "           4       0.80      0.75      0.77       552\n",
      "\n",
      "    accuracy                           0.68      2832\n",
      "   macro avg       0.69      0.69      0.69      2832\n",
      "weighted avg       0.69      0.68      0.69      2832\n",
      "\n",
      "confusion_matrix: \n",
      "[[393  59  43  59  49]\n",
      " [ 38 393  65  36   9]\n",
      " [ 28  80 356  73  29]\n",
      " [ 34  77  59 383  17]\n",
      " [ 39  27  33  40 413]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred_prob = model.predict(x_validation)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "y_validation = np.argmax(y_validation, axis=1)\n",
    "\n",
    "acc = metrics.accuracy_score(y_validation, y_pred)\n",
    "print('accuracy of validation', acc)\n",
    "\n",
    "print('precision, recall, F1 score: ')\n",
    "print(metrics.classification_report(y_validation, y_pred))\n",
    "\n",
    "print('confusion_matrix: ')\n",
    "cm = metrics.confusion_matrix(y_validation, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983ac62-8397-4127-b5da-2daddccd0b37",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1a886de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i m sorry .'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"对不起。\"\n",
    "emotion_mapping = {0: 'joy', 1: 'fear', 2: 'anger', 3: 'sadness', 4: 'neutral'}\n",
    "all_predictions = []\n",
    "\n",
    "translation_result = translate(text)\n",
    "translation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d9e231a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorry</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  id\n",
       "i          1   1\n",
       "m          1   2\n",
       "sorry      1   3\n",
       ".          1   4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_word = lambda x: word_tokenize(x)\n",
    "translation_result=pd.DataFrame(pd.Series(translation_result))\n",
    "translation_result['words'] = translation_result[0].apply(cut_word)\n",
    "\n",
    "j = []\n",
    "for i in translation_result['words']:\n",
    "    j.extend(i)\n",
    "dicts = pd.DataFrame(pd.Series(j).value_counts())\n",
    "dicts['id'] = list(range(1, len(dicts)+1))\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8742ef0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>words</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i m sorry .</td>\n",
       "      <td>[i, m, sorry, .]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             words          sent\n",
       "0  i m sorry .  [i, m, sorry, .]  [1, 2, 3, 4]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sent = lambda x: list(dicts['id'][x])\n",
    "translation_result['sent'] = translation_result['words'].apply(get_sent)\n",
    "translation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcfef9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "Emotion:\t fear\n"
     ]
    }
   ],
   "source": [
    "translation_result['sent'] = list(sequence.pad_sequences(translation_result['sent'], maxlen=maxlen))\n",
    "\n",
    "x_test = np.array(list(translation_result['sent']))\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "y_pred = (y_pred_test > 0.5).astype(int)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "all_predictions.extend(y_pred)\n",
    "\n",
    "emotion_counts = {emotion: all_predictions.count(index) for index, emotion in emotion_mapping.items()}\n",
    "emotion = max(emotion_counts, key=emotion_counts.get)\n",
    "\n",
    "print(\"Emotion:\\t\", emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8edb1-bb61-4f27-ad03-145492a2e3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
